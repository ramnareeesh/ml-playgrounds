{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for classifying red wine based on quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading CSV dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0               7.4             0.700         0.00             1.9      0.076   \n1               7.8             0.880         0.00             2.6      0.098   \n2               7.8             0.760         0.04             2.3      0.092   \n3              11.2             0.280         0.56             1.9      0.075   \n4               7.4             0.700         0.00             1.9      0.076   \n...             ...               ...          ...             ...        ...   \n1594            6.2             0.600         0.08             2.0      0.090   \n1595            5.9             0.550         0.10             2.2      0.062   \n1596            6.3             0.510         0.13             2.3      0.076   \n1597            5.9             0.645         0.12             2.0      0.075   \n1598            6.0             0.310         0.47             3.6      0.067   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                    11.0                  34.0  0.99780  3.51       0.56   \n1                    25.0                  67.0  0.99680  3.20       0.68   \n2                    15.0                  54.0  0.99700  3.26       0.65   \n3                    17.0                  60.0  0.99800  3.16       0.58   \n4                    11.0                  34.0  0.99780  3.51       0.56   \n...                   ...                   ...      ...   ...        ...   \n1594                 32.0                  44.0  0.99490  3.45       0.58   \n1595                 39.0                  51.0  0.99512  3.52       0.76   \n1596                 29.0                  40.0  0.99574  3.42       0.75   \n1597                 32.0                  44.0  0.99547  3.57       0.71   \n1598                 18.0                  42.0  0.99549  3.39       0.66   \n\n      alcohol  quality  \n0         9.4        5  \n1         9.8        5  \n2         9.8        5  \n3         9.8        6  \n4         9.4        5  \n...       ...      ...  \n1594     10.5        5  \n1595     11.2        6  \n1596     11.0        6  \n1597     10.2        5  \n1598     11.0        6  \n\n[1599 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.880</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.99680</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.760</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.99700</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.280</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.99800</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1594</th>\n      <td>6.2</td>\n      <td>0.600</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>0.090</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99490</td>\n      <td>3.45</td>\n      <td>0.58</td>\n      <td>10.5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>5.9</td>\n      <td>0.550</td>\n      <td>0.10</td>\n      <td>2.2</td>\n      <td>0.062</td>\n      <td>39.0</td>\n      <td>51.0</td>\n      <td>0.99512</td>\n      <td>3.52</td>\n      <td>0.76</td>\n      <td>11.2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>6.3</td>\n      <td>0.510</td>\n      <td>0.13</td>\n      <td>2.3</td>\n      <td>0.076</td>\n      <td>29.0</td>\n      <td>40.0</td>\n      <td>0.99574</td>\n      <td>3.42</td>\n      <td>0.75</td>\n      <td>11.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>5.9</td>\n      <td>0.645</td>\n      <td>0.12</td>\n      <td>2.0</td>\n      <td>0.075</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99547</td>\n      <td>3.57</td>\n      <td>0.71</td>\n      <td>10.2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>6.0</td>\n      <td>0.310</td>\n      <td>0.47</td>\n      <td>3.6</td>\n      <td>0.067</td>\n      <td>18.0</td>\n      <td>42.0</td>\n      <td>0.99549</td>\n      <td>3.39</td>\n      <td>0.66</td>\n      <td>11.0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>1599 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.read_csv(\"winequality-red.csv\")\n",
    "wine_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "quality\n5    681\n6    638\n7    199\n4     53\n8     18\n3     10\nName: count, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df[\"quality\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filtering the Values of Quality\n",
    "<=6 -> 0\n",
    "greater than 6 -> 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def categorise(x):\n",
    "    if x <= 6:\n",
    "        return 0\n",
    "    return 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "wine_df[\"quality\"] = wine_df[\"quality\"].apply(categorise)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "quality\n0    1382\n1     217\nName: count, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df[\"quality\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting Dependent and Independent Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X = wine_df.iloc[:, :-1].values\n",
    "y = wine_df.iloc[:, -1].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting of Dataset into Test and Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 8.4  ,  0.745,  0.11 , ...,  3.19 ,  0.82 ,  9.6  ],\n       [ 7.6  ,  0.43 ,  0.29 , ...,  3.4  ,  0.64 ,  9.5  ],\n       [ 8.4  ,  0.56 ,  0.04 , ...,  3.22 ,  0.44 ,  9.6  ],\n       ...,\n       [ 7.9  ,  0.57 ,  0.31 , ...,  3.29 ,  0.69 ,  9.5  ],\n       [13.   ,  0.47 ,  0.49 , ...,  3.3  ,  0.68 , 12.7  ],\n       [ 9.8  ,  0.98 ,  0.32 , ...,  3.25 ,  0.48 ,  9.4  ]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, ..., 0, 0, 0])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MMS = MinMaxScaler()\n",
    "X_train = MMS.fit_transform(X=X_train)\n",
    "X_test = MMS.fit_transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.33035714, 0.42808219, 0.11      , ..., 0.35433071, 0.27607362,\n        0.18461538],\n       [0.25892857, 0.21232877, 0.29      , ..., 0.51968504, 0.16564417,\n        0.16923077],\n       [0.33035714, 0.30136986, 0.04      , ..., 0.37795276, 0.04294479,\n        0.18461538],\n       ...,\n       [0.28571429, 0.30821918, 0.31      , ..., 0.43307087, 0.19631902,\n        0.16923077],\n       [0.74107143, 0.23972603, 0.49      , ..., 0.44094488, 0.19018405,\n        0.66153846],\n       [0.45535714, 0.5890411 , 0.32      , ..., 0.4015748 , 0.06748466,\n        0.15384615]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.56363636, 0.35227273, 0.5443038 , ..., 0.28431373, 0.42574257,\n        0.42857143],\n       [0.31818182, 0.75      , 0.        , ..., 0.47058824, 0.1980198 ,\n        0.21428571],\n       [0.40909091, 0.14772727, 0.41772152, ..., 0.37254902, 0.5049505 ,\n        0.58928571],\n       ...,\n       [0.24545455, 0.23295455, 0.62025316, ..., 0.47058824, 0.44554455,\n        0.46428571],\n       [1.        , 0.59659091, 0.96202532, ..., 0.06862745, 0.34653465,\n        0.5       ],\n       [0.27272727, 0.30681818, 0.36708861, ..., 0.50980392, 0.30693069,\n        0.19642857]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ->  1027\n",
      "1  ->  172\n"
     ]
    }
   ],
   "source": [
    "unique_val, counts = np.unique(y_train, return_counts=True)\n",
    "for i in range(len(unique_val)):\n",
    "    print(unique_val[i], \" -> \", counts[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (685895961.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[15], line 9\u001B[0;36m\u001B[0m\n\u001B[0;31m    def weight_gradient(self, weight):\u001B[0m\n\u001B[0m                                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class Logistic_Regression:\n",
    "    def __init__(self, learning_rate=0.1, iter=100):\n",
    "        self.learnRate = learning_rate\n",
    "        self.epochs = iter\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        no_samples = len(X)\n",
    "        no_features = len(X[0])\n",
    "        self.weights = np.zeros(no_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            # forward propagation\n",
    "            weighted_sum = np.dot(X, self.weights) + self.bias\n",
    "            predicted = self.sigmoid(weighted_sum)\n",
    "\n",
    "\n",
    "\n",
    "    def weight_gradient(self, weight):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
