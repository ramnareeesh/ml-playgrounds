{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/231508 [00:00<?, ?B/s]\u001b[A\n",
      "  4%|▎         | 8192/231508 [00:00<00:06, 34405.19B/s]\u001b[A\n",
      " 26%|██▌       | 60416/231508 [00:00<00:01, 140613.80B/s]\u001b[A\n",
      "100%|██████████| 231508/231508 [00:00<00:00, 310708.17B/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/440473133 [00:00<?, ?B/s]\u001b[A\n",
      "  0%|          | 2048/440473133 [00:00<21:34:33, 5670.81B/s]\u001b[A\n",
      "  0%|          | 18432/440473133 [00:00<2:36:59, 46758.42B/s]\u001b[A\n",
      "  0%|          | 26624/440473133 [00:00<3:11:30, 38330.61B/s]\u001b[A\n",
      "  0%|          | 34816/440473133 [00:01<3:49:49, 31940.26B/s]\u001b[A\n",
      "  0%|          | 52224/440473133 [00:01<3:20:12, 36664.59B/s]\u001b[A\n",
      "  0%|          | 69632/440473133 [00:01<2:44:59, 44489.06B/s]\u001b[A\n",
      "  0%|          | 87040/440473133 [00:02<3:41:39, 33114.19B/s]\u001b[A\n",
      "  0%|          | 104448/440473133 [00:02<2:59:53, 40800.99B/s]\u001b[A\n",
      "  0%|          | 121856/440473133 [00:03<3:14:26, 37745.63B/s]\u001b[A\n",
      "  0%|          | 156672/440473133 [00:04<2:55:14, 41878.77B/s]\u001b[A\n",
      "  0%|          | 191488/440473133 [00:04<2:05:20, 58545.35B/s]\u001b[A\n",
      "  0%|          | 243712/440473133 [00:04<1:23:45, 87603.88B/s]\u001b[A\n",
      "  0%|          | 313344/440473133 [00:04<57:00, 128686.21B/s] \u001b[A\n",
      "  0%|          | 382976/440473133 [00:05<44:25, 165100.69B/s]\u001b[A\n",
      "  0%|          | 452608/440473133 [00:05<35:56, 204079.02B/s]\u001b[A\n",
      "  0%|          | 504832/440473133 [00:05<29:56, 244967.78B/s]\u001b[A\n",
      "  0%|          | 557056/440473133 [00:05<29:21, 249745.57B/s]\u001b[A\n",
      "  0%|          | 591872/440473133 [00:05<27:55, 262500.99B/s]\u001b[A\n",
      "  0%|          | 661504/440473133 [00:05<22:55, 319798.14B/s]\u001b[A\n",
      "  0%|          | 698368/440473133 [00:05<23:38, 309988.77B/s]\u001b[A\n",
      "  0%|          | 783360/440473133 [00:06<18:51, 388648.66B/s]\u001b[A\n",
      "  0%|          | 825344/440473133 [00:06<19:57, 366999.26B/s]\u001b[A\n",
      "  0%|          | 922624/440473133 [00:06<16:33, 442643.46B/s]\u001b[A\n",
      "  0%|          | 973824/440473133 [00:06<19:00, 385326.31B/s]\u001b[A\n",
      "  0%|          | 1044480/440473133 [00:06<16:23, 446989.34B/s]\u001b[A\n",
      "  0%|          | 1131520/440473133 [00:06<17:36, 416037.38B/s]\u001b[A\n",
      "  0%|          | 1305600/440473133 [00:07<10:58, 667128.72B/s]\u001b[A\n",
      "  0%|          | 1385472/440473133 [00:07<15:36, 468922.99B/s]\u001b[A\n",
      "  0%|          | 1448960/440473133 [00:07<26:19, 277902.49B/s]\u001b[A\n",
      "  0%|          | 1497088/440473133 [00:08<26:01, 281129.74B/s]\u001b[A\n",
      "  0%|          | 1539072/440473133 [00:08<37:51, 193222.49B/s]\u001b[A\n",
      "  0%|          | 1584128/440473133 [00:08<36:30, 200317.90B/s]\u001b[A\n",
      "  0%|          | 1705984/440473133 [00:08<25:03, 291876.81B/s]\u001b[A\n",
      "  0%|          | 1862656/440473133 [00:09<15:38, 467444.43B/s]\u001b[A\n",
      "  0%|          | 1936384/440473133 [00:09<16:36, 440180.85B/s]\u001b[A\n",
      "  1%|          | 2228224/440473133 [00:09<08:36, 848421.72B/s]\u001b[A\n",
      "  1%|          | 2354176/440473133 [00:09<10:49, 674934.51B/s]\u001b[A\n",
      "  1%|          | 2767872/440473133 [00:10<08:21, 873383.65B/s]\u001b[A\n",
      "  1%|          | 3063808/440473133 [00:10<06:18, 1155040.95B/s]\u001b[A\n",
      "  1%|          | 3290112/440473133 [00:10<06:14, 1166110.86B/s]\u001b[A\n",
      "  1%|          | 3434496/440473133 [00:10<06:26, 1131627.68B/s]\u001b[A\n",
      "  1%|          | 3812352/440473133 [00:10<04:39, 1559849.97B/s]\u001b[A\n",
      "  1%|          | 3997696/440473133 [00:10<05:31, 1315696.64B/s]\u001b[A\n",
      "  1%|          | 4323328/440473133 [00:10<04:19, 1683161.45B/s]\u001b[A\n",
      "  1%|          | 4529152/440473133 [00:11<05:42, 1273847.58B/s]\u001b[A\n",
      "  1%|          | 4847616/440473133 [00:11<04:29, 1614690.67B/s]\u001b[A\n",
      "  1%|          | 5058560/440473133 [00:11<06:05, 1190408.05B/s]\u001b[A\n",
      "  1%|          | 5306368/440473133 [00:11<05:14, 1383720.14B/s]\u001b[A\n",
      "  1%|▏         | 5552128/440473133 [00:12<06:58, 1038498.29B/s]\u001b[A\n",
      "  1%|▏         | 5879808/440473133 [00:12<05:16, 1373522.57B/s]\u001b[A\n",
      "  1%|▏         | 6080512/440473133 [00:12<06:28, 1116697.00B/s]\u001b[A\n",
      "  1%|▏         | 6535168/440473133 [00:12<04:20, 1664392.48B/s]\u001b[A\n",
      "  2%|▏         | 6784000/440473133 [00:12<05:15, 1375857.57B/s]\u001b[A\n",
      "  2%|▏         | 7124992/440473133 [00:13<07:02, 1024552.49B/s]\u001b[A\n",
      "  2%|▏         | 7286784/440473133 [00:14<13:12, 546592.35B/s] \u001b[A\n",
      "  2%|▏         | 7616512/440473133 [00:14<09:22, 768948.54B/s]\u001b[A\n",
      "  2%|▏         | 7795712/440473133 [00:14<09:48, 734675.32B/s]\u001b[A\n",
      "  2%|▏         | 8091648/440473133 [00:14<07:22, 977723.68B/s]\u001b[A\n",
      "  2%|▏         | 8279040/440473133 [00:14<07:32, 955163.26B/s]\u001b[A\n",
      "  2%|▏         | 8587264/440473133 [00:15<05:41, 1262941.60B/s]\u001b[A\n",
      "  2%|▏         | 8790016/440473133 [00:15<06:49, 1054320.33B/s]\u001b[A\n",
      "  2%|▏         | 8953856/440473133 [00:16<18:02, 398496.68B/s] \u001b[A\n",
      "  2%|▏         | 9320448/440473133 [00:16<11:23, 630397.58B/s]\u001b[A\n",
      "  2%|▏         | 9505792/440473133 [00:17<11:19, 634643.30B/s]\u001b[A\n",
      "  2%|▏         | 9655296/440473133 [00:17<12:11, 588627.79B/s]\u001b[A\n",
      "  2%|▏         | 9774080/440473133 [00:18<19:26, 369141.37B/s]\u001b[A\n",
      "  2%|▏         | 9861120/440473133 [00:18<19:46, 363015.34B/s]\u001b[A\n",
      "  2%|▏         | 10008576/440473133 [00:18<15:30, 462744.23B/s]\u001b[A\n",
      "  2%|▏         | 10101760/440473133 [00:18<16:43, 428870.10B/s]\u001b[A\n",
      "  2%|▏         | 10188800/440473133 [00:18<14:54, 480792.44B/s]\u001b[A\n",
      "  2%|▏         | 10270720/440473133 [00:19<14:45, 485640.82B/s]\u001b[A\n",
      "  2%|▏         | 10418176/440473133 [00:19<11:49, 606434.79B/s]\u001b[A\n",
      "  2%|▏         | 10500096/440473133 [00:19<11:34, 619080.05B/s]\u001b[A\n",
      "  2%|▏         | 10663936/440473133 [00:19<09:08, 783702.71B/s]\u001b[A\n",
      "  2%|▏         | 10762240/440473133 [00:19<09:09, 781816.64B/s]\u001b[A\n",
      "  2%|▏         | 10958848/440473133 [00:19<07:21, 973918.02B/s]\u001b[A\n",
      "  3%|▎         | 11066368/440473133 [00:19<07:46, 920610.17B/s]\u001b[A\n",
      "  3%|▎         | 11254784/440473133 [00:19<06:15, 1143588.44B/s]\u001b[A\n",
      "  3%|▎         | 11384832/440473133 [00:20<07:02, 1015858.34B/s]\u001b[A\n",
      "  3%|▎         | 11581440/440473133 [00:20<05:53, 1213339.48B/s]\u001b[A\n",
      "  3%|▎         | 11728896/440473133 [00:20<06:49, 1047425.56B/s]\u001b[A\n",
      "  3%|▎         | 11845632/440473133 [00:20<07:29, 952996.19B/s] \u001b[A\n",
      "  3%|▎         | 12105728/440473133 [00:20<05:32, 1289767.45B/s]\u001b[A\n",
      "  3%|▎         | 12250112/440473133 [00:21<17:07, 416897.88B/s] \u001b[A\n",
      "  3%|▎         | 12417024/440473133 [00:21<13:37, 523892.40B/s]\u001b[A\n",
      "  3%|▎         | 12530688/440473133 [00:22<14:27, 493457.04B/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/transformers/modeling_utils.py:318\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# redirect to the cache, if necessary\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_path(archive_file, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, force_download\u001b[38;5;241m=\u001b[39mforce_download, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_model_archive_map:\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/transformers/file_utils.py:176\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies)\u001b[0m\n\u001b[1;32m    172\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlparse(url_or_filename)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_from_cache(url_or_filename, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, force_download\u001b[38;5;241m=\u001b[39mforce_download, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m url_or_filename\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/transformers/file_utils.py:302\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies)\u001b[0m\n\u001b[1;32m    300\u001b[0m     s3_get(url, temp_file, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     http_get(url, temp_file, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we are copying the file before closing it, so flush to avoid truncation\u001b[39;00m\n\u001b[1;32m    305\u001b[0m temp_file\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/transformers/file_utils.py:242\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies)\u001b[0m\n\u001b[1;32m    240\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(content_length) \u001b[38;5;28;01mif\u001b[39;00m content_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    241\u001b[0m progress \u001b[38;5;241m=\u001b[39m tqdm(unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mtotal)\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m req\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m):\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk: \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(amt\u001b[38;5;241m=\u001b[39mamt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_read(amt) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token at position 4: on\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "\n",
    "# Load pre-trained BERT model for masked language modeling\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Input text\n",
    "text = \"The cube was [MASK] the desk\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "# Predict the masked token\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    predictions = outputs.logits\n",
    "\n",
    "# Get the predicted token IDs for the masked positions\n",
    "masked_positions = [i for i, token_id in enumerate(inputs[0]) if token_id == tokenizer.mask_token_id]\n",
    "predicted_token_ids = torch.argmax(predictions[0, masked_positions], dim=-1)\n",
    "\n",
    "# Convert predicted token IDs back to tokens\n",
    "predicted_tokens = [tokenizer.convert_ids_to_tokens(token_id.item()) for token_id in predicted_token_ids]\n",
    "\n",
    "# Print the predicted tokens\n",
    "for position, token in zip(masked_positions, predicted_tokens):\n",
    "    print(f\"Predicted token at position {position}: {token}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2-xl\"  # You can use different sizes of GPT-2 models\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Prompt for text generation\n",
    "prompt = \"Introduce yourself\"\n",
    "\n",
    "# Tokenize input prompt\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate text using the model\n",
    "max_length = 20  # Maximum number of tokens in the generated text\n",
    "attention_mask = torch.ones(input_ids.shape, device=device)\n",
    "output = model.generate(input_ids, attention_mask = attention_mask, max_length=max_length, num_return_sequences=1, pad_token_id = 500)\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model_name = \"gpt2-medium\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Number of parameters:\", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
