{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"/Users/ramnaresh/Documents/GitHub/ml-playgrounds/iris.data\", sep=\",\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m ARIMA(iris_df, order\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/statsmodels/tsa/arima/model.py:158\u001B[0m, in \u001B[0;36mARIMA.__init__\u001B[0;34m(self, endog, exog, order, seasonal_order, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001B[0m\n\u001B[1;32m    151\u001B[0m     trend \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;66;03m# Construct the specification\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;66;03m# (don't pass specific values of enforce stationarity/invertibility,\u001B[39;00m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;66;03m# because we don't actually want to restrict the estimators based on\u001B[39;00m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;66;03m# this criteria. Instead, we'll just make sure that the parameter\u001B[39;00m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;66;03m# estimates from those methods satisfy the criteria.)\u001B[39;00m\n\u001B[0;32m--> 158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spec_arima \u001B[38;5;241m=\u001B[39m SARIMAXSpecification(\n\u001B[1;32m    159\u001B[0m     endog, exog\u001B[38;5;241m=\u001B[39mexog, order\u001B[38;5;241m=\u001B[39morder, seasonal_order\u001B[38;5;241m=\u001B[39mseasonal_order,\n\u001B[1;32m    160\u001B[0m     trend\u001B[38;5;241m=\u001B[39mtrend, enforce_stationarity\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, enforce_invertibility\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    161\u001B[0m     concentrate_scale\u001B[38;5;241m=\u001B[39mconcentrate_scale, trend_offset\u001B[38;5;241m=\u001B[39mtrend_offset,\n\u001B[1;32m    162\u001B[0m     dates\u001B[38;5;241m=\u001B[39mdates, freq\u001B[38;5;241m=\u001B[39mfreq, missing\u001B[38;5;241m=\u001B[39mmissing,\n\u001B[1;32m    163\u001B[0m     validate_specification\u001B[38;5;241m=\u001B[39mvalidate_specification)\n\u001B[1;32m    164\u001B[0m exog \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spec_arima\u001B[38;5;241m.\u001B[39m_model\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39morig_exog\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# Raise an error if we have a constant in an integrated model\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/statsmodels/tsa/arima/specification.py:446\u001B[0m, in \u001B[0;36mSARIMAXSpecification.__init__\u001B[0;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001B[0m\n\u001B[1;32m    441\u001B[0m         exog \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mc_[trend_data, exog]\n\u001B[1;32m    443\u001B[0m \u001B[38;5;66;03m# Create an underlying time series model, to handle endog / exog,\u001B[39;00m\n\u001B[1;32m    444\u001B[0m \u001B[38;5;66;03m# especially validating shapes, retrieving names, and potentially\u001B[39;00m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;66;03m# providing us with a time series index\u001B[39;00m\n\u001B[0;32m--> 446\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model \u001B[38;5;241m=\u001B[39m TimeSeriesModel(endog, exog\u001B[38;5;241m=\u001B[39mexog, dates\u001B[38;5;241m=\u001B[39mdates, freq\u001B[38;5;241m=\u001B[39mfreq,\n\u001B[1;32m    447\u001B[0m                               missing\u001B[38;5;241m=\u001B[39mmissing)\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendog \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m faux_endog \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model\u001B[38;5;241m.\u001B[39mendog\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model\u001B[38;5;241m.\u001B[39mexog\n",
      "File \u001B[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:470\u001B[0m, in \u001B[0;36mTimeSeriesModel.__init__\u001B[0;34m(self, endog, exog, dates, freq, missing, **kwargs)\u001B[0m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    468\u001B[0m     \u001B[38;5;28mself\u001B[39m, endog, exog\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dates\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    469\u001B[0m ):\n\u001B[0;32m--> 470\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(endog, exog, missing\u001B[38;5;241m=\u001B[39mmissing, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;66;03m# Date handling in indexes\u001B[39;00m\n\u001B[1;32m    473\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_dates(dates, freq)\n",
      "File \u001B[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/statsmodels/base/model.py:270\u001B[0m, in \u001B[0;36mLikelihoodModel.__init__\u001B[0;34m(self, endog, exog, **kwargs)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, endog, exog\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 270\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(endog, exog, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitialize()\n",
      "File \u001B[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/statsmodels/base/model.py:95\u001B[0m, in \u001B[0;36mModel.__init__\u001B[0;34m(self, endog, exog, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m missing \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmissing\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     94\u001B[0m hasconst \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhasconst\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m---> 95\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_data(endog, exog, missing, hasconst,\n\u001B[1;32m     96\u001B[0m                               \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_constant \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mk_constant\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mexog\n",
      "File \u001B[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/statsmodels/base/model.py:135\u001B[0m, in \u001B[0;36mModel._handle_data\u001B[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_handle_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, endog, exog, missing, hasconst, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 135\u001B[0m     data \u001B[38;5;241m=\u001B[39m handle_data(endog, exog, missing, hasconst, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001B[39;00m\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
      "File \u001B[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/statsmodels/base/data.py:675\u001B[0m, in \u001B[0;36mhandle_data\u001B[0;34m(endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[1;32m    672\u001B[0m     exog \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(exog)\n\u001B[1;32m    674\u001B[0m klass \u001B[38;5;241m=\u001B[39m handle_data_class_factory(endog, exog)\n\u001B[0;32m--> 675\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m klass(endog, exog\u001B[38;5;241m=\u001B[39mexog, missing\u001B[38;5;241m=\u001B[39mmissing, hasconst\u001B[38;5;241m=\u001B[39mhasconst,\n\u001B[1;32m    676\u001B[0m              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/statsmodels/base/data.py:84\u001B[0m, in \u001B[0;36mModelData.__init__\u001B[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_endog \u001B[38;5;241m=\u001B[39m endog\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_exog \u001B[38;5;241m=\u001B[39m exog\n\u001B[0;32m---> 84\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendog, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_endog_exog(endog, exog)\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconst_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_constant \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/statsmodels/base/data.py:509\u001B[0m, in \u001B[0;36mPandasData._convert_endog_exog\u001B[0;34m(self, endog, exog)\u001B[0m\n\u001B[1;32m    507\u001B[0m exog \u001B[38;5;241m=\u001B[39m exog \u001B[38;5;28;01mif\u001B[39;00m exog \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray(exog)\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m endog\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m exog \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m exog\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m--> 509\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPandas data cast to numpy dtype of object. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    510\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCheck input data with np.asarray(data).\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m(PandasData, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m_convert_endog_exog(endog, exog)\n",
      "\u001B[0;31mValueError\u001B[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "model = ARIMA(iris_df, order=(2, 1, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
